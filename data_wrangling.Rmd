---
title: "data_wrangling"
author: "Francis"
date: "11/10/2018"
output: github_document
editor_options: 
  chunk_output_type: console
---

After consideration, the `admissions.csv` database seems really interesting. It is useful to analyze the  connection between mutiple factors and death.
```{r}
library(tidyverse)
library(devtools)
library(readr)
library(lubridate)

knitr::opts_chunk$set(echo = TRUE)
```

# MIMIC3

### Import data
```{r}
admissions <- 
  read_csv("./database/admissions.csv") %>% 
  janitor::clean_names()
names(admissions)
  
# The year should be delt with to become normal. The discharge time means the time when the patient leave the hospital.


# see types
class(admissions$admittime)
class(admissions$dischtime)
class(admissions$deathtime)
class(admissions$admission_type) 
class(admissions$insurance)
class(admissions$religion)
class(admissions$ethnicity)
class(admissions$edregtime)
class(admissions$edouttime)

```
All of them are factors.



### Tidy data
```{r}
#Create year, month, day variables
admissions <- 
  admissions %>% 
  separate(admittime, into = c("admittime_year", "admittime_month", "admittime_day"), sep = "-")
admissions <- 
  admissions %>% 
  separate(dischtime, into = c("dischtime_year", "dischtime_month", "dischtime_day"), sep = "-") %>% 
  separate(dischtime_day, into = c("dischtime_day", "dischtime_time"), sep = " ")
admissions <- 
  admissions %>% 
  separate(deathtime, into = c("deathtime_year", "deathtime_month", "deathtime_day"), sep = "-") %>% 
  separate(deathtime_day, into = c("deathtime_day", "deathtime_time"), sep = " ")
admissions <- 
  admissions %>% 
  separate(edregtime, into = c("edregtime_year", "edregtime_month", "edregtime_day"), sep = "-") %>% 
  separate(edregtime_day, into = c("edregtime_day", "edregtime_time"), sep = " ")
admissions <- 
  admissions %>% 
  separate(edouttime, into = c("edouttime_year", "edouttime_month", "edouttime_day"), sep = "-") %>% 
  separate(edouttime_day, into = c("edouttime_day", "edouttime_time"), sep = " ")

# Correct year to normal
admissions <- 
  admissions %>% 
  mutate(admittime_year = as.numeric(admittime_year) - 200, dischtime_year = as.numeric(dischtime_year) - 200, deathtime_year = as.numeric(deathtime_year) - 200, edregtime_year = as.numeric(edregtime_year) - 200, edouttime_year = as.numeric(edouttime_year) - 200)
# Take a look
head(admissions)
```





### linear regression

```{r}
# read original data
admissions_origin <- 
  read_csv("./database/admissions.csv") %>% 
  janitor::clean_names()


# add a death factor and duration factor
admissions_death <- 
  mutate(admissions_origin, living = is.na(admissions_origin$deathtime), hospitaltime =  admissions_origin$dischtime - admissions_origin$admittime, edtime = admissions_origin$edouttime - admissions_origin$edregtime)



```



```{r}
# glance data
skimr::skim(admissions_death)

```



```{r, eval=FALSE}


### try logistic regression step by step.

#SLR

living_lm1 <- 
  lm(living ~ admission_type, data = admissions_death)
summary(living_lm1)    

living_lm2 <- 
  lm(living ~ admission_location, data = admissions_death)
summary(living_lm2)

living_lm3 <- 
  lm(living ~ insurance, data = admissions_death)
summary(living_lm3)

living_lm4 <- 
  lm(living ~ language, data = na.omit(select(admissions_death, living, language)))
summary(living_lm4)

living_lm5 <- 
  lm(living ~ religion, data = admissions_death)
summary(living_lm5)

living_lm6 <- 
  lm(living ~ marital_status, data = admissions_death)
summary(living_lm6)

living_lm7 <- 
  lm(living ~ ethnicity, data = admissions_death)
summary(living_lm7)

living_lm8 <- 
  lm(living ~ diagnosis, data = admissions_death)
summary(living_lm8)

living_lm9 <- 
  lm(living ~ hospital_expire_flag, data = admissions_death)
summary(living_lm9)

living_lm10 <- 
  lm(living ~ has_chartevents_data, data = admissions_death)
summary(living_lm10)

living_lm11 <- 
  lm(living ~ hospitaltime, data = admissions_death)
summary(living_lm11)

living_lm12 <- 
  lm(living ~ edtime, data = filter(edtime > 0))
summary(living_lm12)
```



```{r eval=FALSE}
#MLR

living_mlr <- 
  lm(living ~ hospitaltime + admission_type + admission_location + insurance + language + religion + marital_status + ethnicity + edtime + hospital_expire_flag + has_chartevents_data + insurance, data = admissions_death)
summary(living_mlr)


coefficients(living_mlr)
confint(living_mlr)
fitted(living_mlr)
residuals(living_mlr)
anova(living_mlr)
vcov(living_mlr)
influence(living_mlr)

ggplot(living_mlr)
```



```{r eval=FALSE}
# K-fold cross-validation
library(DAAG)
cv.lm(df = admissions_death, living_mlr, m = 3) # 3 fold cross-validation



```{r}
# step seems not working???
```




```{r eval=FALSE}
# All Subsets Regression
library(leaps)
attach(admissions_death)
leaps <- 
  regsubsets(living ~ hospitaltime + admission_type + admission_location + insurance + language + religion + marital_status + ethnicity + edtime + hospital_expire_flag + has_chartevents_data + insurance, data = admissions_death, nbest = 10)
# view results 
summary(leaps)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic.
plot(leaps,scale = "r2")
# plot statistic by subset size 
library(car)
subsets(leaps, statistic = "rsq")
```



```{r eval=FALSE}
# Calculate Relative Importance for Each Predictor
library(relaimpo)
calc.relimp(fit,type=c("lmg","last","first","pratt"),
   rela=TRUE)
```


```{r eval=FALSE}
# Bootstrap Measures of Relative Importance (1000 samples) 
boot <- boot.relimp(admissions_death, b = 1000, type = c("lmg", 
  "last", "first", "pratt"), rank = TRUE, 
  diff = TRUE, rela = TRUE)
booteval.relimp(boot) # print result
plot(booteval.relimp(boot,sort=TRUE)) # plot result
```







































#OpenFDA

### Import OpenFDA
```{r}
# Already installed openfda data
# Load OpenFDA
library(openfda)


library(jsonlite)
fda <- 
  fromJSON("https://api.fda.gov/drug/event.json") %>% 
  janitor::clean_names()

names(fda$results)

```
There are `r length(fda$results)` observations in the `event` dataset under `drug`, they are: `r names(fda$results)`.


