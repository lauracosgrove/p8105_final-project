---
title: "Generating severity scores"
author: "Laura Cosgrove"
date: "11/20/2018"
output: github_document
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(RPostgreSQL)
library(tidyverse)
library(dbplyr)
library(lubridate)
```


```{r dbconnect}
# Load configuration settings
dbdriver <- 'PostgreSQL'
host  <- '127.0.0.1'
port  <- '5432'
user  <- 'postgres'
password <- 'postgres'
dbname <- 'mimic'
schema <- 'mimiciii'
# Connect to the database using the configuration settings
con <- dbConnect(dbDriver(dbdriver), dbname = dbname, host = host, port = port, 
                 user = user, password = password)
# Set the default schema
dbExecute(con, paste("SET search_path TO ", schema, sep=" "))
```

Set this database as the connection for all future sql chunks:

```{r}
knitr::opts_chunk$set(connection = "con")
```

The above chunk works if you use knitr to generate the analysis! But in building the analysis it is maybe better to run your query by saving the sql query as a character object then using `dbGetQuery`.

Credit for SQL code authoring is not mine:

We need to generate some views into the database before the query to generate the severity scores works.
--  1) uofirstday - generated by urine-output-first-day.sql
--  2) ventdurations - generated by ventilation-durations.sql
--  3) vitalsfirstday - generated by vitals-first-day.sql
--  4) gcsfirstday - generated by gcs-first-day.sql
--  5) labsfirstday - generated by labs-first-day.sql
--  6) bloodgasarterialfirstday - generated by blood-gas-first-day-arterial.sql

```{r, eval = FALSE}
urine_view <- read_file("./database/mimic-code/concepts/firstday/urine-output-first-day.sql")
ventdurations_view <- read_file("./database/mimic-code/concepts/durations/ventilation-durations.sql")
vitals_view <- read_file("./database/mimic-code/concepts/firstday/vitals-first-day.sql")
gcs_view <- read_file("./database/mimic-code/concepts/firstday/gcs-first-day.sql")
labs_view <- read_file("./database/mimic-code/concepts/firstday/labs-first-day.sql")
bloodgasarterial_view <- read_file("./database/mimic-code/concepts/firstday/blood-gas-first-day-arterial.sql")
sapsii_view <- read_file("./database/mimic-code/concepts/severityscores/sapsii.sql")


#Generate materialized views
dbGetQuery(con, urine_view)
dbGetQuery(con, ventdurations_view)
dbGetQuery(con, vitals_view)
dbGetQuery(con, gcs_view)
dbGetQuery(con, labs_view)
dbGetQuery(con, bloodgasarterial_view)
dbGetQuery(con, sapsii_view)

```

Rewrite `sapsii_view` in R using `dbplyr`?

```{r}

```


```{r view}
#View sapsii_data
sapsii_query <- "SELECT *
              FROM sapsii i;"
sapsii_data <- as.tibble(dbGetQuery(con, sapsii_query))
write_csv(sapsii_data, path = "./database/sapsii.csv")

```

OMG Finally!

Plot distribution:

```{r}
sapsii_data %>% 
  ggplot(aes(x = sapsii)) + 
  geom_histogram()
```

A note in the SQL file is the following: 
Note:
The score is calculated for *all* ICU patients, with the assumption that the user will subselect appropriate ICUSTAY_IDs.
For example, the score is calculated for neonates, but it is likely inappropriate to actually use the score values for these patients.

```{sql connection=con}
SELECT *
FROM sapsii i
```


### Visualize how fractions of death increase 

```{r}
admissions <- read_csv("./database/data/ADMISSIONS.csv.gz") %>% 
  janitor::clean_names()
patients <- read_csv("./database/data/PATIENTS.csv.gz") %>% 
  janitor::clean_names()
sapsii <- read_csv("./database/sapsii.csv") %>% 
  janitor::clean_names()


admissions %>% 
  inner_join(., patients, by = "subject_id") %>% 
  filter(has_chartevents_data == 1) %>% 
  inner_join(., sapsii, by = "hadm_id") %>% 
  mutate(target = if_else(deathtime %in% NA, 0, 1),
         predictor = sapsii) %>%
  select(subject_id.x, target, predictor) %>% 
  group_by(predictor) %>% 
  summarize(deaths = sum(target),
            n = n()) %>% 
  mutate(frac_deaths = deaths/n) %>% 
  ggplot(aes(x = predictor, y = frac_deaths)) +
  geom_point(aes(color = n)) + 
  labs(x = "SAPS II Score",
       y = "Mortality Fraction", 
       title = "Predicting Mortality of ICU Patients with First-Day SAPS II scores") +
  theme_bw()
  

```

Repeat for other severity scores:

(Note: must run document once before knitting, but eval is set to false so the views aren't re-loaded every time you knit.)
```{r, eval = FALSE}
sofa_view <- read_file("./database/mimic-code/concepts/severityscores/sofa.sql")
lods_view <- read_file("./database/mimic-code/concepts/severityscores/lods.sql")
saps_view <- read_file("./database/mimic-code/concepts/severityscores/saps.sql")
apsiii_view <- read_file("./database/mimic-code/concepts/severityscores/apsiii.sql")
oasis_view <- read_file("./database/mimic-code/concepts/severityscores/oasis.sql")

#SOFA needs echo data 
echodata_view <- read_file("./database/mimic-code/concepts/echo-data.sql")

dbGetQuery(con, echodata_view)
dbGetQuery(con, sofa_view)

#LODS
dbGetQuery(con, lods_view)

#SAPS needs ventilated first day
ventfirstday_view <- read_file("./database/mimic-code/concepts/firstday/ventilation-first-day.sql")
dbGetQuery(con, ventfirstday_view)
dbGetQuery(con, saps_view)

# APSIII  
dbGetQuery(con, apsiii_view)

# OASIS  
dbGetQuery(con, oasis_view)

```

As before, read all the data from the generated materialized views into tibbles:

```{r}
#SOFA
sofa_query <- "SELECT *
              FROM sofa i;"
sofa_data <- as.tibble(dbGetQuery(con, sofa_query))

#LODS
lods_query <- "SELECT *
              FROM lods i;"
lods_data <- as.tibble(dbGetQuery(con, lods_query))

#SAPS
saps_query <- "SELECT *
              FROM saps i;"
saps_data <- as.tibble(dbGetQuery(con, saps_query))

# APSIII  
apsiii_query <- "SELECT *
              FROM apsiii i;"
apsiii_data <- as.tibble(dbGetQuery(con, apsiii_query))

#OASIS
oasis_query <- "SELECT *
              FROM oasis i;"
oasis_data <- as.tibble(dbGetQuery(con, oasis_query))
```

Plot curves for all other scores

```{r}
# I should create a nested df where I can map the inner join and generate multiple plots in the same code chunk

admissions %>% 
  inner_join(., patients, by = "subject_id") %>% 
  filter(has_chartevents_data == 1) %>% 
  inner_join(., sofa_data, by = "hadm_id") %>% 
  mutate(target = if_else(deathtime %in% NA, 0, 1),
         predictor = sofa) %>%
  select(subject_id.x, target, predictor) %>% 
  group_by(predictor) %>% 
  summarize(deaths = sum(target),
            n = n()) %>% 
  mutate(frac_deaths = deaths/n) %>% 
  ggplot(aes(x = predictor, y = frac_deaths)) +
  geom_point(aes(color = n)) + 
  theme_bw()

# Make a big datasheet?
all_scores <- admissions %>% 
  inner_join(., patients, by = "subject_id") %>% 
  inner_join(., sapsii_data, by = "hadm_id") %>% 
  inner_join(., sofa_data, by = "hadm_id") %>% 
  inner_join(., lods_data, by = "hadm_id") %>% 
  inner_join(., saps_data, by = "hadm_id") %>% 
  inner_join(., apsiii_data, by = "hadm_id") %>% 
  inner_join(., oasis_data, by = "hadm_id") %>% 
  mutate(target = if_else(deathtime %in% NA, 0, 1)) %>% 
  select(subject_id.x, hadm_id, target, sapsii, saps, sofa, lods, apsiii, oasis)

all_scores %>% 
  select(sapsii:oasis) %>% 
  cor()

```

```{r plot, fig.width= 12 , fig.asp = 0.4}
all_scores %>% 
  distinct(hadm_id, .keep_all = TRUE) %>% 
  gather(key = score, value, sapsii, saps, sofa, lods, apsiii, oasis) %>% 
  group_by(score, value) %>% 
  summarize(deaths = sum(target), 
            n = n()) %>% 
  mutate(frac_deaths = deaths/n) %>% 
  ggplot(aes(x = value, y = frac_deaths)) + 
  geom_point(aes(color = n)) +
  facet_grid(~score)

```

## Individual mortality prediction

It's fine just as a quick gut check to see how fraction of deaths increase over the distributions of the various severity scores. But how do the scores perform based on their original authored likelihoods?

### SAPS II

We'll start with the SAPS II score. 

Individual mortality prediction for the SAPS II score is defined by its authors to be: 

log([pr(death)][1 - pr(death)]) = -7.7631 + 0.07237*SAPSII + 0.9971*log(1 + SAPSII)

A mortality prediction algorithm is said to have adequate discrimination if it tends to assign higher severity scores to patients that died in the hospital compared to those that did not. To evaluate discrimination, we'll visualize the probability of death as predicted by the SAPSII score versus the actual proportion of patients who died with that SAPSII score.

```{r}
sapsii_data %>% 
  mutate(prob_death = exp(-7.7631 + 0.07237*sapsii + 0.9971*log(1 + sapsii))/(1 + exp(-7.7631 + 0.07237*sapsii + 0.9971*log(1 + sapsii)))) %>% 
  inner_join(admissions, by = "hadm_id") %>% 
  mutate(mortality = if_else(deathtime %in% NA, 0, 1),
         hosp_los = admittime %--% dischtime) %>% 
  select(hadm_id, sapsii, prob_death, hosp_los, mortality, starts_with("admission"), diagnosis) %>% 
  group_by(sapsii) %>% 
  add_tally(mortality) %>% 
  rename(mortality_by_group = n) %>% 
  add_tally() %>% 
  mutate(prop_death = mortality_by_group/n) %>% 
  select(sapsii, prob_death, prop_death) %>% 
  ggplot(aes(x = prob_death, y = prop_death)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  labs(x = "Probability of Death ")
  
  


  
```


